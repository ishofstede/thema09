---
title: "thema09_logboek"
author: "Isabella Hofstede"
date: "2023-09-13"
output:
  html_document: default
  pdf_document: default
---
# week 1
For the purpose of this project a few packages and libraries will be installed. 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}
install.packages("ggplot2")       
install.packages("GGally")
install.packages("codebookr")
```

```{r include=FALSE}
library(ggplot2) #use for plotting correlation and scatter plot
library(GGally)
library(grid)
library(gridExtra)
library(tidyverse) #used for ANOVA
library(codebookr) #used for codebook
library(dplyr, warn.conflicts = FALSE) #used for codebook
library(haven) #used for codebook
```

## Context:
A dataset has been chosen with the aim of creating a supervised ML model for classification. We picked a dataset on bird classification by bonestructure. There are different types of birds, ranging from flying, to swimming, to running birds. For this dataset, birds have been classified into ecological groups according to their habitats. There are 8 ecological groups of birds:

- Swimming Birds;
- Wading Birds;
- Terrestrial Birds;
- Raptors;
- Scansorial Birds;
- Singing Birds;
- Cursorial Birds (not included in dataset);
- Marine Birds (not included in dataset).

The first 6 groups are covered by this dataset. Birds belonging to different ecological groups have different appearances: flying birds have strong wings and wading birds have long legs. Their living habits are somewhat reflected in their bones' shapes. We may think of examining the underlying relationship between sizes of bones and ecological groups , and recognizing birds's ecological groups by their bone structure.

## Status of data
The dataset comes from kaggle (https://www.kaggle.com/datasets/zhangjuefei/birds-bones-and-living-habits). It is made up of measurements of bird skeletons from collections of the Natural History Museum of Los Angeles County (data provided by Dr. D. Liu of Beijing Museum of Natural History). It is a 420x10 size continuous values unbalanced multi-class dataset, meaning there are 420 birds contained in this dataset, each bird is represented by 10 measurements (features):

- Huml and Humw: Length and Diameter of Humerus;
- Ulnal and Ulnaw: Length and Diameter of Ulna;
- Feml and Femw: Length and Diameter of Femur;
- Tibl and Tilw: Length and Diameter of Tibiotarsus;
- Tarl and Tarw: Length and Diameter of Tarsometatarsus.

The class attribute is "type", referring to the ecological group. The bird skeletons belong to 21 orders, 153 genera, 245 species. Each bird has a label for its ecological group:

- SW: Swimming Birds;
- W: Wading Birds;
- T: Terrestrial Birds;
- R: Raptors;
- P: Scansorial Birds;
- SO: Singing Birds.

## Data exploration
Firstly, we need to have an overview of our data. Pictured below is a summary of the dataset:
```{r}
#load the data
bird_data <- read.table('bird.csv', sep=",", header = 1)
```

Pictured below is a codebook with all the relevant information;
```{r}
codebook <- readr::read_delim("bird.csv", delim = ",", show_col_types = F)
pander::pander(codebook[, 1:11], style = "rmarkdown")
```

A first look shows a wide range of sizes and just a few missing values. The significance of these entries must be checked.
```{r}
#checking total NA's in dataset
sum(is.na(bird_data))
```
There are 15 missing values. Let's see which birds those values are attatched to;

```{r}
#checking which types of birds have missing data
missing_data_type <- bird_data$type[apply(is.na(bird_data), 1, any)]
missing_data_type
```

So there are a total of 7 birds with missing values. This means there are a total 420 entries with 15 missing values spread across 7 birds. The missing values are the measurements of certain bones but none of the main attribute data; "type", is missing. Apparently there are a few birds with "missing bones". This means a choice must be made to discard the missing data or perform imputation, which means replacing the missing data with substitutions. However 7 out of 420 means the observations with missing values account for less than 2% of the dataset, and may be insignificant enough to remove entirely. Let's also think about why the data is missing; is it significant to specific types of birds or is the data quite random? 

These missing values are most likely field data that was not properly formatted into the csv file. Since the SO (songbirds) are over represented in the data, it seems fine to remove the entries with missing values. The missing values also have no real meaning, since every bird is supposed to have the same amount of bones, which means the missing values are just bones that were not measured.

## Cleaning dataset
The 7 missing values and the id column shall be removed and a new CSV file will be created. This will be the clean dataset with which we will perform machine learning. 
```{r}
#remove the ID's and NA's
clean_bird_data <- na.omit(bird_data)
clean_bird_data <- subset(clean_bird_data, select = -id)
#check if any missing values are left
colSums(is.na(clean_bird_data))
#write the csv file with cleaned dataset. 
write.csv(clean_bird_data, "bird_clean.csv", row.names = F)
```

All the missing values have been removed and the cleaned data can now be used for further analysis.

## Class distribution 
We need to check whether or not the data is equally distributed between the types of birds. 
```{r}
#create a barchart per species
ggplot(clean_bird_data, aes(x = type)) + geom_bar(fill = "black") + 
  labs(title = "distribution of bird species", x = "species", y = "count")
```

On a glance we can already see that the distribution is not equal, it is seemingly all over the place. There is an over representation of songbirds (SO) and Swimming birds (SW). Terrestrial birds (T) are the group with the least instances. Wading birds (W), Raptos (R) and Scansorial birds (P) are somewhere in between. The 6 classes are not equally distributed. To remedy this, we may double the lowest group or half the biggest group if the training models are insufficiently trained. For now though, we shall use the dataset as is without any further changes. 

## Variation and distributions 
To check the distribution of the data we can make boxplots of bonetypes for each type of bird. We want to look for outliers in each type. 
```{r warning=FALSE}
#boxplot of all bonemeasurements
p1 <- ggplot(clean_bird_data, aes(x = type, y = huml)) + geom_boxplot() 
p2 <- ggplot(clean_bird_data, aes(x = type, y = humw)) + geom_boxplot() 
p3 <- ggplot(clean_bird_data, aes(x = type, y = ulnal)) + geom_boxplot() 
p4 <- ggplot(clean_bird_data, aes(x = type, y = ulnaw)) + geom_boxplot()
p5 <- ggplot(clean_bird_data, aes(x = type, y = feml)) + geom_boxplot() 
p6 <- ggplot(clean_bird_data, aes(x = type, y = femw)) + geom_boxplot() 
p7 <- ggplot(clean_bird_data, aes(x = type, y = tibl)) + geom_boxplot()
p8 <- ggplot(clean_bird_data, aes(x = type, y = tibw)) + geom_boxplot() 
p9 <- ggplot(clean_bird_data, aes(x = type, y = tarl)) + geom_boxplot()
p10 <- ggplot(clean_bird_data, aes(x = type, y = tarw)) + geom_boxplot()
grid.arrange(p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, nrow = 2)
```

The data seems to have a lot of outliers, to see whether or not this is relevant we can do a log transformation to check the significance.


```{r warning=FALSE}
#logtransformed boxplot of all bonemeasurements  
plog1 <- ggplot(clean_bird_data, aes(y = huml,x = type)) + geom_boxplot() + 
  scale_y_continuous(trans = "log10")
plog2 <-ggplot(clean_bird_data, aes(y = humw,x = type)) + geom_boxplot() + 
  scale_y_continuous(trans = "log10")
plog3 <- ggplot(clean_bird_data, aes(y = ulnal,x = type)) + geom_boxplot() + 
  scale_y_continuous(trans = "log10")
plog4 <- ggplot(clean_bird_data, aes(y = ulnaw,x = type)) + geom_boxplot() + 
  scale_y_continuous(trans = "log10")
plog5 <- ggplot(clean_bird_data, aes(y = feml,x = type)) + geom_boxplot() + 
  scale_y_continuous(trans = "log10")
plog6 <- ggplot(clean_bird_data, aes(y = femw,x = type)) + geom_boxplot() + 
  scale_y_continuous(trans = "log10")
plog7 <-ggplot(clean_bird_data, aes(y = tibl,x = type)) + geom_boxplot() + 
  scale_y_continuous(trans = "log10")
plog8 <- ggplot(clean_bird_data, aes(y = tibw,x = type)) + geom_boxplot() + 
  scale_y_continuous(trans = "log10")
plog9 <- ggplot(clean_bird_data, aes(y = tarl,x = type)) + geom_boxplot() + 
  scale_y_continuous(trans = "log10")
plog10 <-ggplot(clean_bird_data, aes(y = tarw,x = type)) + geom_boxplot() + 
  scale_y_continuous(trans = "log10")
grid.arrange(plog1, plog2, plog3, plog4, plog5, plog6, plog7, plog8, plog9,
             plog10, nrow = 2)
```

Most outliers of the SW group have been removed entirely. There are still plenty of outliers in T group, but since it's the smallest group no instances shall be removed. It is safe to assume that the outliers are actually just bigger and smaller birds. From now on we can assume the outliers are not significant enough to be removed and thus the regular dataset will be used for machine learning. This data can be used for trees, but if these algorithms prove insufficient, logtransformed data may be used for Naive Bayes.

How can we see if a variable is informative for machine learning? To find out, we will perform an ANOVA on each bone type per bird type and sort the p-values. This will help us determine the most useful values for prediction, even though the distribution it is scewed. (can use t-values as well to order it)
```{r}
#aov.models = clean_bird_data[ , -grep("type", names(clean_bird_data))] %>%
#  map(~ aov(clean_bird_data$type ~ .x))
```

!!!is een variable informatief voor ml? zoek het uit; annova doen op elke bot type PER type vogel. Op p-waarden sorteren. helpful voor trees. Ordenen bij meest en minst verschillende waardes. 



## Correlation 
Before checking, the logical assumption would be that the data is highly correlated, since all birds have similar bone structures and the birds within a specific type are going to look even more similar. To be sure, however, we can use a scatterplot to visualize the distribution of the bone sizes and the relationship between them. 

```{r, figures-side, fig.show="hold", out.width="50%", warning=FALSE}
#create a scatterplot of the bone lengths and widths. 
ggplot(clean_bird_data,aes(x=huml,y=humw,color=type))+geom_point()+
  geom_smooth()
ggplot(clean_bird_data,aes(x=ulnal,y=ulnaw,color=type))+geom_point()+
  geom_smooth()
ggplot(clean_bird_data,aes(x=feml,y=femw,color=type))+geom_point()+
  geom_smooth()
ggplot(clean_bird_data,aes(x=tibl,y=tibw,color=type))+geom_point()+
  geom_smooth()
ggplot(clean_bird_data,aes(x=tarl,y=tarw,color=type))+geom_point()+
  geom_smooth()
```
The scatterplot suggest that there is a correlation between bird types and their bone structures. We can also look at a correlation matrix to see precisely how highly correlated our data is:

```{r, warning=FALSE}
#correlation matrix (start from 2 because id has not been removed yet)
ggcorr(clean_bird_data, label = TRUE)
```

Unsurprisingly the correlation matrix also gave us a large positive correlation between all our measurements. This is of course because when birds get bigger, so do their bone measurements. The swimming birds (SW), however, seem a lot bigger than the others. It makes sense that SW has a lot of different measurements because big birds, like swans, and small birds, like coots, are both classified as swimming birds. Since the correlation between different bird species is so high, classification could prove difficult. We need to keep this in mind when choosing out model. 

## Research Question 
Based on the exploratory data analysis the research question will be: Using machine learning algorithms, which bone measurements are most informative for classifying birds into ecological groups?

Which then follows that the null hypothesis will be: There is no significant relationship between bird bone measurements and their ecological groups, and bone measurements are not informative for accurate classification. 

And so the alternative hypothesis: There is a significant relationship between bird bone measurements and their ecological groups, and bone measurements are informative for accurate classification.

# Week 4

## Quality metrics 
To assess the performance of our algorithm there are a few metrics that are commonly used; accuracy, speed, precision/recall and F1-score. Nearly all these values can be recorded in a confusion matrix. For our project, accuracy is the most important metric to assess the quality of the algorithm. Speed is not a metric that is important for this relatively low amount of data. 

## Machine learning in wekka
Considering our dataset is highly imbalanced, we can already guess that trees will perform better than any other algorithms. Regardless, the selection of machine learning models has been made to cover to include representatives of all classifier categories:

- ZeroR (baseline measurement)
- oneR (baseline measurement)
- J48 
- Naive Bayes
- SMO
- K-Nearest Neighbor (IBK)
- Simple Logistic Regression
- Random forest

Some of these algorithms, like Naive Bayes,  will not work well with imbalanced datasets. We could fix this by either under- or oversampling our dataset, but the remaining algorithms like trees and logistic regression are known to perform better on imbalanced datasets. First we will compare all the algorithms and their default values in Wekka with the clean dataset using Wekka experimenter. 

```{r}
wekka_default <- read.csv("wekka_exp_default.csv", header=T)
results_default <- aggregate(wekka_default$Percent_correct, list(wekka_default$Key_Scheme), mean)
colnames(results_default) <- c("algorithm", "percentage correct")
results_default
```

All the chosen algorithms scored higher than ZeroR and OneR. The most promising results come from the K-Nearest Neighbor (89.16% correct), Simple logistic (85.24% correct) and the Random Forest (84.54% correct) algorithm. We will use these for further analysis. 

# Week 5 

## Attribute selection
Loading in the clean dataset, we use the Wekka Explorer to select attributes. WE mix attribute evaluators with 
=== Attribute Selection on all input data ===

Search Method:
	Attribute ranking.

Attribute Evaluator (supervised, Class (nominal): 11 type):
	OneR feature evaluator.

	Using 10 fold cross validation for evaluating attributes.
	Minimum bucket size for OneR: 6

Ranked attributes:
54.9637   1 huml
53.0266   4 ulnaw
52.7845   2 humw
51.3317   3 ulnal
49.6368   7 tibl
47.6998  10 tarw
47.6998   5 feml
46.4891   8 tibw
44.7942   6 femw
42.8571   9 tarl

For the one OneR feature evaluator + ranker method it seems huml and ulnaw is the highest scoring attribute.  


=== Attribute Selection on all input data ===
Search Method:
	Exhaustive Search.
	Start set: no attributes
	Number of evaluations: 1024
	Merit of best subset found:    0.427

Attribute Subset Evaluator (supervised, Class (nominal): 11 type):
	CFS Subset Evaluator
	Including locally predictive attributes

Selected attributes: 1,3,4,10 : 4
                     huml
                     ulnal
                     ulnaw
                     tarw

For CFS subset evaluator + exhaustive search method again it seems huml and unlal are highest scoring.


=== Attribute Selection on all input data ===

Search Method:
	Exhaustive Search.
	Start set: no attributes
	Number of evaluations: 1024
	Merit of best subset found:    0.897

Attribute Subset Evaluator (supervised, Class (nominal): 11 type):
	Wrapper Subset Evaluator
	Learning scheme: weka.classifiers.lazy.IBk
	Scheme options: -K 1 -W 0 -A weka.core.neighboursearch.LinearNNSearch -A "weka.core.EuclideanDistance -R first-last" 
	Subset evaluation: classification accuracy
	Number of folds for accuracy estimation: 5


Selected attributes: 1,2,3,5,6,7,9,10 : 8
                     huml
                     humw
                     ulnal
                     feml
                     femw
                     tibl
                     tarl
                     tarw

For Wrapper subset evaluator + exhaustive search it seems huml and humw are the highest scoring. 

Overall it seems the length and width of the humerus and ulna are the most significant measurements for accurate classification of bird groups. These bones are located in the sings of the bird. It makes sense that wingspan would determine the group that the bird belongs to. Lagging behind in ranking are the femur and tibiotarsus bones, which are located in the legs of the bird. 


## stappenplan 
OneRattribute
Ranker + gainratio 

CFs subset evaluator
met groepjes ranken 
zeggen veel over classe maar onderling verschillend. 

CfssubsetEval met ExhaustiveSearch
                     
gooi bij je data alles eruit hevalve huml, save het als arff  file
ga naar experimenter, set nieuw experiment op, gooi alle data erin, cleaned, en single variables, en 1 variable
add new -> zeroR, Naivebayes, Classificationviaclustering (simpleKmeans), simplelogistic, forrest
kruisvalideren. 
100 number repetitions. 
run het 
het final model is bijv "kmeans" met huml en ulna variabelen. 
check bij comarison field wat er allemaal in zit 

ranking 
cfs 
wrapper 
CorrelationAttributeEVal no class

wekka true positive rate and false positive rate plotten ROC curve (kan ook screenshotje toevoegen in R)
 